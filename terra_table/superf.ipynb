{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import Levenshtein as lv\n",
    "\n",
    "from collections import defaultdict as ddict, Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saud Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SD = pd.read_excel(\"ext.xlsx\")\n",
    "TD = pd.read_csv(\"sample.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SD.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SD.Data_Source_saud_edited.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SD_IDs = ['BamID_modified_no_dashes','BamID_modified','sample_original','Sauds_BamID_x',\n",
    "       'sample_id','Sauds_BamID_y','Patient.ID','BamID_modified_discovery','unique_ID']\n",
    "SD[SD_IDs].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SD_full_IDs = ['BamID_modified_no_dashes','BamID_modified','sample_original','unique_ID']\n",
    "SD[SD_full_IDs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = SD['BamID_modified'] == SD['sample_original']\n",
    "print(matches.sum())\n",
    "SD[~matches][['BamID_modified','sample_original']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terra Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TD.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TD_IDs = ['entity:sample_id','BamSampleID','edited_participant_id','edited_sample_id','participant_id','Sauds_BamID','participant']\n",
    "TD[TD_IDs].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TD_full_IDs=['entity:sample_id','BamSampleID','edited_participant_id', 'participant']\n",
    "TD[TD_full_IDs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2589-2*1341"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_id_lists(TDIs, SDIs):\n",
    "    lmn = max([len(x) for x in TDIs])\n",
    "    rn = max([len(x) for x in SDIs])\n",
    "\n",
    "    print((\" \"*lmn) + \" | \" + \" | \".join([f'{x: <{rn}}' for x in SDIs]))\n",
    "\n",
    "    for x in TDIs:\n",
    "        print(f'{x: <{lmn}}', end='')\n",
    "        T_unique = pd.Series(TD[x].unique())\n",
    "        Tn = len(T_unique)\n",
    "        for y in SDIs:\n",
    "            found = T_unique.isin(SD[y]).sum()\n",
    "            datum = f\"{found}/{Tn}\"\n",
    "            print(f' | {datum: >{rn}}', end ='')\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_id_lists(TD_IDs,SD_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_id_lists(TD_full_IDs, SD_full_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_work = TD[['entity:sample_id','BamSampleID','edited_participant_id', 'participant']].copy()\n",
    "T_work[\"Source\"] = np.nan\n",
    "T_work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_work = SD[['sample_original','Data_Source_saud_edited']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "parcol = ['edited_participant_id', 'participant'][1]\n",
    "###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed = []\n",
    "multi = []\n",
    "nopid = []\n",
    "histish = ddict(int)\n",
    "\n",
    "for _, id, source in S_work.itertuples():\n",
    "    id_hit = T_work[T_work.BamSampleID == id]\n",
    "    if len(id_hit) == 0:\n",
    "        missed.append(id)\n",
    "        continue\n",
    "\n",
    "    if len(id_hit) > 1:\n",
    "        multi.append((id, len(id_hit)))\n",
    "\n",
    "    n = 0\n",
    "    for _, sid, bid, pid, s0 in id_hit[['entity:sample_id','BamSampleID', parcol, 'Source']].itertuples():\n",
    "        if pd.isna(pid):\n",
    "            nopid.append((sid, bid))\n",
    "            continue\n",
    "\n",
    "        if not pd.isna(s0):\n",
    "            continue\n",
    "\n",
    "        rows = T_work[parcol] == pid\n",
    "        n += rows.sum()\n",
    "        T_work.loc[rows, \"Source\"] = source\n",
    "\n",
    "    histish[n] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In Sauds, not matched to Terra BamSampleID:\", len(missed))\n",
    "print(\"In Sauds, BamSampleID listed multiple times in Terra:\", len(multi))\n",
    "print(len(nopid))\n",
    "print(histish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_work.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What just happened?\n",
    "So, according to the `compare_id_lists(...)` results, 1245 unique BamSampleIDs (of 1446 unique<sup>1</sup>) matched sample_originals (of 1341 unique) from Saud's spreadsheet.\n",
    "This means 96 of saud's rows (whatever those represent) did not match to any of Terra's _verbatim_.\n",
    "Further, 131 samples with a matched BamSampleID did not have an edited_participant_ID.\n",
    "\n",
    "Of the remaining 1114 (=1341-96-131), 2092 samples were able to be traced to the source through fully informed sample_original → BamSampleIDs → edited_participant_id chains.\n",
    "\n",
    "<sup>1</sup> There is one duplicate BamSampleID (SC_9065 Normal), we'll see what's up with that.\n",
    "\n",
    "Let's break it down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yesBam_noPar = pd.isna(T_work[parcol]) & ~pd.isna(T_work.BamSampleID)\n",
    "len(T_work[yesBam_noPar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noBam_noPar = pd.isna(T_work[parcol]) & pd.isna(T_work.BamSampleID)\n",
    "len(T_work[noBam_noPar])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the 147 Terra samples with no participant ID (which appears to be used to pair Tumor/Normal samples):\n",
    " - 134 entries with a BamSampleID don't have a participant ID (131 matched to Saud's data)\n",
    " - 13 samples have neither a BamSampleID nor an edited_participant_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break down of the edited_participant_id by multiplicity\n",
    "par_sets = T_work.groupby(parcol)['entity:sample_id'].count()\n",
    "Counter(par_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have:\n",
    "- 277 participants with single samples\n",
    "- 1006 with two samples\n",
    "- 51 with three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_intersect(n):\n",
    "    who = par_sets[par_sets == n].index                        # participants with n samples\n",
    "    qui = T_work[T_work[parcol].isin(who)]       # samples of those participants\n",
    "    qui2 = qui[~pd.isna(qui.BamSampleID)]                      # ... with BamSampleIDs\n",
    "    qui3 = qui2[qui2.BamSampleID.isin(S_work.sample_original)] # ... found in Saud's Spreadsheet \n",
    "\n",
    "    print(len(qui), len(qui2), len(qui3))\n",
    "    return qui3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1, 2, 3]:\n",
    "    do_intersect(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the 277 samples in singles, 204 have BamSampleIDs. 186 BamSampleIDs are in Saud's sample_originals\n",
    "\n",
    "Of the 2012 samples in the 1006 pairs, 1007 have BamSampleIDs. 878 of those are in Saud's\n",
    "\n",
    "153 samples in triples, 102 have BamSampleIDs, 50 in Saud's\n",
    "\n",
    "The numbers suggest in most cases one of a pair has a BamSampleID and 2 of each triple have BamSampleIDs, let's check.\n",
    "Further, one of each of the triples appears to also be in Saud's, except one case (is it our double?)\n",
    "\n",
    "Regardless, we have $1114 = 186 + 878 + 50$ and $2092 = 186 + 878*2 + 50*3$, showing that the tool worked as expected, informing participant samples with no BamSampleID of the source via a sample that did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "who = par_sets[par_sets == 3].index\n",
    "qui = T_work[T_work[parcol].isin(who)]\n",
    "bam_break = qui.groupby(parcol)['BamSampleID'].count()\n",
    "Counter(bam_break)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "who = par_sets[par_sets == 2].index\n",
    "qui = T_work[T_work[parcol].isin(who)]\n",
    "bam_break = qui.groupby(parcol)['BamSampleID'].count()\n",
    "print(Counter(bam_break))\n",
    "bam_break[bam_break == 2].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So all of the triples have one sample missing a BamSampleID, and 1005 of the 1006 pairs are split.\n",
    "There is one pair for which both BamSampleIDs are filled, PRAD-6115392_dot_0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "who = par_sets[par_sets == 3].index                         # participants with n samples\n",
    "qui = T_work[T_work[parcol].isin(who)]        # samples of those participants\n",
    "qui2 = qui[~pd.isna(qui.BamSampleID)]                       # ... with BamSampleIDs\n",
    "qui3 = qui2[~qui2.BamSampleID.isin(S_work.sample_original)] # ... NOT found in Saud's\n",
    "qui3[qui3.BamSampleID == 'SC_9065 Normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "who = par_sets[par_sets == 2].index                         # participants with n samples\n",
    "qui = T_work[T_work[parcol].isin(who)]        # samples of those participants\n",
    "qui2 = qui[~pd.isna(qui.BamSampleID)].copy()                # ... with BamSampleIDs\n",
    "qui2['In Saud'] = qui2.BamSampleID.isin(S_work.sample_original)\n",
    "qui2[qui2[parcol] == 'RP-1532_PCProject_0521'] # 'PRAD-6115392_dot_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "who = par_sets[par_sets == 3].index\n",
    "'PRAD-6115392_dot_0' in who"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The duplicated BamSampleID _is_ part of a triple, and those BamSampleIDs are _not_ in Saud's spreadsheet.\n",
    "\n",
    "The one pair for which both BamSampleIDs are present has one of those in Saud's and one not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now What?\n",
    "\n",
    "### Matched Saud\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr><th colspan=2 scope=\"row\">BamSampleID</th><th colspan=\"2\" scope=\"col\">yes</th><th scope=\"col\">no</th></tr>\n",
    "    <tr style=\"border-bottom: double\"><th colspan=2 scope=\"row\">sample_original</th><th scope=\"col\">unmatched</th><th scope=\"col\">matched</th><td/><td>96</td></tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr><th rowspan=4 scope=\"row\">edited_participant_id<br>multiplicity</th><th>0</th><td>3</td><td>131</td><td>13</td></tr>\n",
    "    <tr><th scope=\"row\">1</th><td>18</td><td style=\"background:#00ff0011\">186</td><td>73</td></tr>\n",
    "    <tr><th scope=\"row\">2</th><td>129</td><td style=\"background:#00ff0011\">878</td><td>1005</td></tr>\n",
    "    <tr><th scope=\"row\">3</th><td>52</td><td style=\"background:#00ff0011\">50</td><td>51</td></tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "### Source Assigned\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr><th colspan=2 scope=\"row\">BamSampleID</th><th colspan=\"2\" scope=\"col\">yes</th><th scope=\"col\">no</th></tr>\n",
    "    <tr style=\"border-bottom: double\"><th colspan=2 scope=\"row\">sourced</th><th scope=\"col\">no</th><th scope=\"col\">yes</th><th>yes</th><th>no</th></tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr><th rowspan=4 scope=\"row\">edited_participant_id<br>multiplicity</th><th>0</th><td>134</td><td>0</td><td>0</td><td>13</td></tr>\n",
    "    <tr><th scope=\"row\">1</th><td>18</td><td style=\"background:#00ff0011\">186</td><td style=\"background:#00ff0011\">0</td><td>73</td></tr>\n",
    "    <tr><th scope=\"row\">2</th><td>128</td><td style=\"background:#00ff0011\">879</td><td style=\"background:#00ff0011\">877</td><td>128</td></tr>\n",
    "    <tr><th scope=\"row\">3</th><td>2</td><td style=\"background:#00ff0011\">100</td><td style=\"background:#00ff0011\">50</td><td>1</td></tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "- check the 96 saud samples to see if and where they land in the Terra sample set\n",
    "- check the 147 samples with no participant id\n",
    "  - could assign the source for 131 without a listed participant\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sourced(n):\n",
    "    who = par_sets[par_sets == n].index                        # participants with n samples\n",
    "    qui = T_work[T_work[parcol].isin(who)]       # samples of those participants\n",
    "    qui2 = qui[pd.isna(qui.BamSampleID)]                      # ... with BamSampleIDs\n",
    "    qui3 = qui2[~pd.isna(qui2.Source)] # ... sourced \n",
    "\n",
    "    print(len(qui), len(qui2), len(qui3))\n",
    "    return qui3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,2,3]:\n",
    "    sourced(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 96 Saud samples not in Terra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsourced = T_work[pd.isna(T_work.Source) & ~pd.isna(T_work.BamSampleID)]['BamSampleID']\n",
    "\n",
    "# Using levenshtein distance to quickly judge similarities\n",
    "for sam in missed:\n",
    "    scores = [(lv.distance(sam, x), x) for x in unsourced]\n",
    "    best = min(scores, key=lambda x:x[0])\n",
    "    print(sam, best)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like some very bizarre space substitution happened\n",
    "found = 0\n",
    "for sam in missed:\n",
    "    sam_fixed = sam.replace(\"_space_\", \" \").strip()\n",
    "    match_ix = unsourced.str.find(sam_fixed)\n",
    "    foundit = (match_ix >= 0).sum()\n",
    "    if foundit > 1: print('bonk', sam, match_ix[match_ix >= 0])\n",
    "    found += foundit >= 1\n",
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_work2 = T_work.copy()\n",
    "missed2 = []\n",
    "multi2 = []\n",
    "nopid2 = []\n",
    "histish2 = Counter()\n",
    "\n",
    "for _, id, source in S_work[S_work.sample_original.isin(missed)].itertuples():\n",
    "    idf = id.replace(\"_space_\", \" \").strip()\n",
    "    id_hit = T_work2[T_work2.BamSampleID == idf]\n",
    "    if len(id_hit) == 0:\n",
    "        missed2.append((id,idf))\n",
    "        continue\n",
    "\n",
    "    if len(id_hit) > 1:\n",
    "        multi2.append((idf, len(id_hit)))\n",
    "\n",
    "    n = 0\n",
    "    for _, sid, bid, pid, s0 in id_hit[['entity:sample_id','BamSampleID', parcol, 'Source']].itertuples():\n",
    "        if pd.isna(pid):\n",
    "            nopid2.append((sid, bid))\n",
    "            continue\n",
    "\n",
    "        if not pd.isna(s0):\n",
    "            continue\n",
    "\n",
    "        rows = T_work2[parcol] == pid\n",
    "        n += rows.sum()\n",
    "        T_work2.loc[rows, \"Source\"] = source\n",
    "\n",
    "    histish2[n] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_work2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(histish2)\n",
    "print(multi2)\n",
    "# it reports a 6 because SC_9065 gets hit twice each for 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _,m in missed2:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've matched 91 more from Saud's with a little name fixing; 90 pairs and a triple (our double named),\n",
    "meaning 183 more sourced in the Terra set\n",
    "\n",
    "### Matched Saud\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr><th colspan=2 scope=\"row\">BamSampleID</th><th colspan=\"2\" scope=\"col\">yes</th><th scope=\"col\">no</th></tr>\n",
    "    <tr style=\"border-bottom: double\"><th colspan=2 scope=\"row\">sample_original</th><th scope=\"col\">unmatched</th><th scope=\"col\">matched</th><td/><td>5</td></tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr><th rowspan=4 scope=\"row\">edited_participant_id<br>multiplicity</th><th>0</th><td>3</td><td>131</td><td>13</td></tr>\n",
    "    <tr><th scope=\"row\">1</th><td>18</td><td style=\"background:#00ff0011\">186</td><td>73</td></tr>\n",
    "    <tr><th scope=\"row\">2</th><td>39</td><td style=\"background:#00ff0011\">968</td><td>1005</td></tr>\n",
    "    <tr><th scope=\"row\">3</th><td>50</td><td style=\"background:#00ff0011\">52</td><td>51</td></tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "### Source Assigned\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr><th colspan=2 scope=\"row\">BamSampleID</th><th colspan=\"2\" scope=\"col\">yes</th><th scope=\"col\">no</th></tr>\n",
    "    <tr style=\"border-bottom: double\"><th colspan=2 scope=\"row\">sourced</th><th scope=\"col\">no</th><th scope=\"col\">yes</th><th>yes</th><th>no</th></tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr><th rowspan=4 scope=\"row\">edited_participant_id<br>multiplicity</th><th>0</th><td>134</td><td>0</td><td>0</td><td>13</td></tr>\n",
    "    <tr><th scope=\"row\">1</th><td>18</td><td style=\"background:#00ff0011\">186</td><td style=\"background:#00ff0011\">0</td><td>73</td></tr>\n",
    "    <tr><th scope=\"row\">2</th><td>38</td><td style=\"background:#00ff0011\">969</td><td style=\"background:#00ff0011\">967</td><td>38</td></tr>\n",
    "    <tr><th scope=\"row\">3</th><td>0</td><td style=\"background:#00ff0011\">102</td><td style=\"background:#00ff0011\">51</td><td>0</td></tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_fixed_intersect(n):\n",
    "    who = par_sets[par_sets == n].index                                                    # participants with n samples\n",
    "    qui = T_work2[T_work2[parcol].isin(who)]                                 # samples of those participants\n",
    "    qui2 = qui[pd.isna(qui.BamSampleID)]                                                  # ... with BamSampleIDs\n",
    "    \n",
    "    #qui3 = qui2[qui2.BamSampleID.isin(S_work.sample_original.str.replace(\"_space_\", \" \").str.strip())] # ... found in Saud's\n",
    "    qui3 = qui2[~pd.isna(qui2.Source)]                                                     # ... sourced\n",
    "\n",
    "    print(len(qui), len(qui2), len(qui3))\n",
    "    return qui3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1, 2, 3]:\n",
    "    do_fixed_intersect(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 131 Matched BamSampleIDs w/o edited_participant_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = pd.isna(TD[parcol]) & \\\n",
    "         TD.BamSampleID.isin(SD.sample_original.unique())\n",
    "bsid = TD[filter].BamSampleID.unique()\n",
    "\n",
    "filter = pd.isna(T_work2.Source) & \\\n",
    "         ~pd.isna(T_work2[parcol])\n",
    "unsourced2 = T_work2[filter][parcol].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in bsid:\n",
    "    scores = [(lv.distance(id, x), x) for x in unsourced2]\n",
    "    best = min(scores, key=lambda x:x[0])\n",
    "    print(id, best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# participant column update\n",
    "\n",
    "### Matched Saud\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr><th colspan=2 scope=\"row\">BamSampleID</th><th colspan=\"2\" scope=\"col\">yes</th><th scope=\"col\">no</th></tr>\n",
    "    <tr style=\"border-bottom: double\"><th colspan=2 scope=\"row\">sample_original</th><th scope=\"col\">unmatched</th><th scope=\"col\">matched</th></tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr><th rowspan=4 scope=\"row\">participant<br>multiplicity</th><th>1</th><td>15</td><td style=\"background:#00ff0011\">251</td><td>3</td></tr>\n",
    "    <tr><th scope=\"row\">2</th><td>39</td><td style=\"background:#00ff0011\">1026</td><td>1063</td></tr>\n",
    "    <tr><th scope=\"row\">3</th><td>51</td><td style=\"background:#00ff0011\">65</td><td>74</td></tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "### Source Assigned\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr><th colspan=2 scope=\"row\">BamSampleID</th><th colspan=\"2\" scope=\"col\">yes</th><th scope=\"col\">no</th></tr>\n",
    "    <tr style=\"border-bottom: double\"><th colspan=2 scope=\"row\">sourced</th><th scope=\"col\">no</th><th scope=\"col\">yes</th><th>yes</th><th>no</th></tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr><th rowspan=4 scope=\"row\">edited_participant_id<br>multiplicity</th>\n",
    "      <th scope=\"row\">1</th><td>15</td><td style=\"background:#00ff0011\">251</td><td style=\"background:#00ff0011\">0</td><td>3</td></tr>\n",
    "    <tr><th scope=\"row\">2</th><td>38</td><td style=\"background:#00ff0011\">1027</td><td style=\"background:#00ff0011\">1025</td><td>38</td></tr>\n",
    "    <tr><th scope=\"row\">3</th><td>0</td><td style=\"background:#00ff0011\">116</td><td style=\"background:#00ff0011\">76</td><td>0</td></tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "A lot of the previous discussion is going to look a little non-sensical because I didn't update any of it to reflect the use of the `participant` column over the `edited_participant_id` from the Terra data. That which slips through the gaps. Plus an added fix to the `_space_` fix cleaned up the last five of Saud's not matched to Terra.\n",
    "\n",
    "So what changed? Well, every sample has a participant listed, not an edited_participant_id, meaning the 147 in the original 0 row got pushed down. Potentially, singles and doubles moved to doubles and triples. This in turn let more be linked and sourced through the BamSampleIDs. It left 94 samples, 76 involved in 38 pairs, unsourced. That's lookable, so let's look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_work2[pd.isna(T_work2.Source)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_final = T_work2.set_index('entity:sample_id') \\\n",
    "    .drop(columns='edited_participant_id') \\\n",
    "    .rename(columns={'Source': 'source_study'})\n",
    "T_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_capture_kit = {\n",
    "    \"AAPC\": \"Agilent SureSelectv4\",\n",
    "    \"Broad/Cornell\": \"Agilent SureSelectv4\",\n",
    "    \"CMI\": \"Illumina Nextera Rapid Capture\",\n",
    "    \"Nelson\": \"Roche Nimblegen SeqCap v3\",\n",
    "    \"NEPC\": \"Agilent SureSelectv4\",\n",
    "    \"PROSNEOLCM\": \"Agilent SureSelectv4\",\n",
    "    \"PCF_SU2C\": \"Agilent SureSelectv4\",\n",
    "    \"TCGA\": \"Agilent SureSelectv4\"\n",
    "}\n",
    "with open('justincase' , 'r') as inp:\n",
    "    datum = inp.readlines()[0].strip()\n",
    "\n",
    "capture_kit_target_file = {\n",
    "    \"Agilent SureSelectv4\": f\"gs://{datum}/capture_target_interval_files/SureSelectv4_targets_sorted.bed\",\n",
    "    \"Illumina Nextera Rapid Capture\": f\"gs://{datum}/capture_target_interval_files/NexteraRapidCapture_targets_sorted.bed\",\n",
    "    \"Roche Nimblegen SeqCap v3\": f\"gs://{datum}/capture_target_interval_files/NimblegenSeqCapv3_targets_sorted.bed\"\n",
    "}\n",
    "\n",
    "source_cap_file = {k : capture_kit_target_file[v] for k,v in source_capture_kit.items()}\n",
    "source_cap_file = pd.DataFrame(source_cap_file.items(), columns=[\"source_study\", \"capture_intervals\"]).set_index('source_study')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TD_inputs = TD[[\"entity:sample_id\", \"sample_type\", \"clean_bam_file_capture\", \"clean_bai_file_capture\"]]\\\n",
    "    .set_index('entity:sample_id') \\\n",
    "    .rename(columns={\"clean_bam_file_capture\": \"clean_bam_capture_hg19\", \"clean_bai_file_capture\": \"clean_bai_capture_hg19\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample_Info = T_final.join(source_cap_file, on=\"source_study\").join(TD_inputs)\n",
    "Sample_Info.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample_Info.replace(to_replace={\n",
    "    'clean_bam_capture_hg19' : {'drs://dataguids\\.org/': 'drs://dg.4DFC/'},\n",
    "    'clean_bai_capture_hg19' : {'drs://dataguids\\.org/': 'drs://dg.4DFC/'}},\n",
    "    regex=True, inplace=True)\n",
    "Sample_Info.loc['PRAD-G9-7522-NB']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## no low coverage, post relatedness sample set (1341)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1341.txt', 'r') as inp, \\\n",
    "     open('1341.list', 'w') as out:\n",
    "    corpus = inp.read()\n",
    "    corpus = corpus.replace(', ', '\\n')\n",
    "    out.write(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_low_post_rel = pd.read_csv('1341.list', header=None, names=['entity:sample_id'], index_col=['entity:sample_id'])\n",
    "Sample_Set = no_low_post_rel.join(Sample_Info)\n",
    "Sample_Set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smol = Sample_Set[~pd.isna(Sample_Set.clean_bam_capture_hg19)] \\\n",
    "    .groupby('source_study') \\\n",
    "    .sample(2)\n",
    "smol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smol.to_csv('random_selection.tsv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
